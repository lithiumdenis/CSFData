%% Алгоритмы распознавания ГСВ с неизвестными математическими ожиданиями и одинаковой матрицей ковариации
%%% 1. Задание исходных данных
%% 1.1. Статистические параметры данных
% Анализируется $M$ классов, объекты которых характеризуются $n$ признаками.
% Задаются априорные вероятности гипотез $w_i$ соответствующих классов:
%
% $\begin{array}{cc} p(w_i), & \sum_{i=1}^M p(w_i)=1. \end{array}$
%%
clear all;
close all;
M = 2;              % число классов;
n = 3;              % размерность пространства признаков;
pw = [0.2, 0.8];    % априорные вероятности классов,
pw = pw ./ sum(pw); % исключение некорректного задания априорных вероятностей;
%% 1.2. Априорные значения математических ожиданий и матрицы ковариации классов
% Формируются $M$ векторов математических ожиданий (МО) параметров каждого класса.
% Каждому классу ставится в соответствие случайный вектор мат. ожиданий из $n$ элементов
%
% $\begin{array}{cc} m^{(i)}=(m_1^{(i)},\ldots,m_n^{(i)})^T, & i=1,\ldots,M, \end{array}$
%
% в которых каждый компонент
%
% $\begin{array}{cc} m_j^{(i)}, & j=1,\ldots,n, \end{array}$
%
% содержит значение МО $j$-го параметра $i$-го класса.
% Предполагается, что значения компонентов вектора МО $m^{(i)}$ подчиняются
% нормальному распределению со средним значением $m_0^{(i)}$ и диагональной матрицей ковариации $C_0:$
%
% $\begin{array}{cc} p(m^{(i)})=N(m^{(i)}, m_0^{(i)}, C_0), & i=1,\ldots,M, \end{array}$
%
% При этом расстояние между средними значениями мат. ожиданий соответствующих признаков
% соседних классов полагается равным $d_m:$
%
% $\begin{array}{lcr} m_{0j}^{(k+1)}-m_{0j}^{(k)}=d_m, & k=1,\ldots,M-1, & j=1,\ldots,n, \end{array}$
%
% Векторы средних значений $m_0^{(i)}$ и матрица ковариации $C_0$ распределений мат. ожиданий считаются априорно известными.
%%
dm = 1;                                 % расстояние между средними значениями мат. ожиданий признаков различных классов;
C = [4 -1 -1; -1 4 -1; -1 -1 4];             % матрица ковариации признаков
C0 = diag(diag(C));                     % априорное значение матрицы ковариации признаков (только диагональные элементы);
m0 = [[0 -1 2]' [2 2 1]']; 	% задание векторов априорных средних значений мат. ожиданий признаков;
m = m0 + randncor(n, M, C0);            % генерация случайных векторов МО, распределённых вокруг своих средних значений;

%%% 2. Обучение на основе оценки неизвестных параметров 
%% 2.1. Задание параметров вычислительного эксперимента
% Предполагается проведение испытаний для $L$ значений объема обучающей выборки $Nn:$
%
% $Nn=(Nn_1,\ldots,Nn_L)^T.$
%
% Для каждого значения $N=Nn_l$ осуществляется $H$ реализаций вычислительного эксперимента,
% в ходе которых происходит:
%
% # генерация обучающих выборок каждого класса;
% # оценка значений МО каждого класса на основе соответствующей обучающей выборки методами МП и МАВ;
% # вычисление коэффициентов разделяющей функции на основе полученных оценок;
% # расчёт ошибок распознавания на основе полученных оценок;
% # серия из $K$ статистических испытаний алгоритма распознавания для
% экспериментального вычисления вероятностей ошибок распознавания.
%%
H = 33;                         % число итераций процесса обучения;
K = 1500;                       % количество статистических испытаний алгоритма распознавания;
Nn = [10, 50, 100 .* (1 : 10)]; % объемы обучающей выборки для серии испытаний
L = length(Nn);                	% число выборок
Pt = zeros(M, L);               % матрица ошибок распознавания
Pe = zeros(M, L);               % экспериментальная матрица ошибок распознавания
%% 2.2. Вычисление апостериорной матрицы ковариации мат. ожиданий признаков
% Оценивание вектора неизвестных МО признаков классов методом МАВ при известной матрице
% ковариации признаков $C$ и априорном значении матрицы ковариации распределения МО $C_0$
% предполагает расчёт матрицы ковариации ошибки оценивания МО $C_N$ для каждого значения $N=Nn_l:$
%
% $C_N=C_0(C_0+\frac{1}{N}C)^{-1}\frac{1}{N}C,$
%
% на основе которой вычисляется апостериорная матрица ковариации МО $C^{\prime}:$
%
% $C^{\prime}=C_N+C.$
%%
for l = 1 : L                       % цикл с изменением объема обучающей выборки,
    N = Nn(l);                         	% объем обучающей выборки для текущей итерации;
    m_ = zeros(n, 2);
    mN = zeros(n, 2);
    CN = C0 / (C0 + C / N) * (C / N);   % матрица ковариации ошибки оценивания значений МО;
    C_ = C + CN;                        % апостериорная матрица ковариации C';
    % Реализация процесса обучения на основе статистической выборки
    for h = 1 : H                                   % цикл статистических испытаний процесса обучения,
        % Генерация обучающих выборок 2х классов
        XN1 = repmat(m(:, 1), [1, N]) + randncor(n, N, C);  % обучающая выборка 1го класса;
        XN2 = repmat(m(:, 2), [1, N]) + randncor(n, N, C);  % обучающая выборка 2го класса;
        % Оценка неизвестных параметров
        m_(:, 1) = sum(XN1, 2) / N;                        	% оценка МП для МО 1го класса;
        m_(:, 2) = sum(XN2, 2) / N;                        	% оценка МП для МО 2го класса;
        mN(:, 1) = CN * (C \ m_(:, 1) * N + C0 \ m0(:, 1));	% оценка МАВ для МО 1го класса;
        mN(:, 2) = CN * (C \ m_(:, 2) * N + C0 \ m0(:, 2));	% оценка МАВ для МО 2го класса;        
        %%% 3. Вычисление разделяющих функций и теоретических ошибок распознавания
        %% 3.1. Расчет коэффициентов разделяющих функций
        G1 = zeros(M, n + 1);           % коэффициенты на основе оценкок МП;
        G2 = zeros(M, n + 1);           % коэффициенты на основе оценкок МАВ;
        for i = 1 : M                       % цикл по классам,
            G1(i, 1 : n)= C \ m_(:, i);
            G1(i, n + 1)= -0.5 * m_(:, i)' / C * m_(:, i);
            G2(i, 1 : n)= C_ \ mN(:, i);
            G2(i, n + 1)= -0.5 * mN(:, i)' / C_ * mN(: ,i);
        end;
        l0_ = log(pw(2) / pw(1));
        %% 3.2. Расчёт вероятностей ошибок распознавания 
        % 3.2.1. На основе оценки МП
        h_ = 0.5 * (m_(:, 1) - m_(:, 2))' / C * (m_(:, 1) - m_(:, 2));
        sD_ = sqrt(2 * h_);
        alf_ = normcdf(l0_, h_, sD_);
        bet_ = 1 - normcdf(l0_, -h_, sD_);
        % 3.2.2. На основе оценки МАВ
        hN = 0.5 * (mN(:, 1) - mN(:, 2))' / C_ * (mN(:, 1) - mN(:, 2));
        sDN = sqrt(2 * hN);
        alfN = normcdf(l0_, hN, sDN);
        betN = 1 - normcdf(l0_, -hN, sDN);
        % 3.2.3. Вычисление суммарных вероятностей ошибок распознавания
        Pt(1, l) = Pt(1, l) + pw(1) * alf_ + pw(2) * bet_;  % ошибка для МП;
        Pt(2, l) = Pt(2, l) + pw(1) * alfN + pw(2) * betN;  % ошибка для МАВ;
%%% 4.Тестирование алгоритма методом статистических испытаний
        pe = zeros(2, M);           % Ошибки: 1-я строка для МП, 2-я для МАВ;
        for i = 1 : M                    % цикл по классам,
            % 4.1. Генерация K образов i-го класса
            xs = repmat(m(:, i), [1, K]) + randncor(n, K, C);
            xs = [xs; ones(1, K)];
            for k = 1 : K                   % цикл по числу испытаний алгоритма распознавания,
                x = xs(:, k);
                u1 = G1 * x + log(pw');         % значение разделяющей функции (по МП);
                [i0, i1] = max(u1);             % определение максимума;
                pe(1, i) = pe(1, i) + (i ~= i1);% фиксация результата распознавания;
                u2 = G2 * x + log(pw');         % значение разделяющей функции (по МАВ);
                [i0, i2] = max(u2);             % определение максимума;
                pe(2, i) = pe(2, i) + (i ~= i2);% фиксация результата распознавания;
            end;
        end;
        pe = pe / K;
        % 4.2. Вычисление экспериментальных суммарных вероятностей ошибок распознавания
        Pe(1, l) = Pe(1, l) + pw(1) * pe(1, 1) + pw(2) * pe(1, 2);	% ошибка для МП;
        Pe(2, l) = Pe(2, l) + pw(1) * pe(2, 1) + pw(2) * pe(2, 2);	% ошибка для МАВ;
	end;%по h
end;%по nn
Pt = Pt / H;
Pe = Pe / H;
% 5. Визуализация зависимостей вероятностей ошибок
figure; 
plot(Nn, Pt(1, :), 'b', Nn, Pt(2, :), 'g', Nn, Pe(1, :), 'bp', Nn, Pe(2, :), 'gp'); 
title('Суммарная вероятность ошибок'); 
legend('\alpha (теор)', '\beta (теор)',... 
'\alpha (эксп)', '\beta (эксп)');
% legend('Ошибка для МП (теор)', 'Ошибка для МАВ (теор)',... 
% 'Ошибка для МП (эксп)', 'Ошибка для МАВ (эксп)');